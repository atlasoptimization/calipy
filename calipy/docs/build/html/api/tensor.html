

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>calipy.core.tensor (API) &mdash; calipy 0.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b849a4e9" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=1c40f30e"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="calipy.core.data (API)" href="data.html" />
    <link rel="prev" title="calipy.core.utils" href="generated/calipy.core.utils.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            calipy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installing <strong>CaliPy</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick‑Start Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Core Concepts &amp; Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">CaliPy API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="core.html">calipy.core  (overview)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">calipy.core.tensor  (API)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex"><code class="docutils literal notranslate"><span class="pre">CalipyIndex</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.bound_dims"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.bound_dims</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.expand_to_dims"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.expand_to_dims()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.generate_index_name_dict"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.generate_index_name_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.is_empty"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.is_empty</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.is_null"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.is_null</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.is_reducible"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.is_reducible()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.null"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.null()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndex.reduce_to_dims"><code class="docutils literal notranslate"><span class="pre">CalipyIndex.reduce_to_dims()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.CalipyIndexer"><code class="docutils literal notranslate"><span class="pre">CalipyIndexer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndexer.convert_indextensor_to_tuple"><code class="docutils literal notranslate"><span class="pre">CalipyIndexer.convert_indextensor_to_tuple()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndexer.convert_slice_to_indextensor"><code class="docutils literal notranslate"><span class="pre">CalipyIndexer.convert_slice_to_indextensor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyIndexer.convert_tuple_to_indextensor"><code class="docutils literal notranslate"><span class="pre">CalipyIndexer.convert_tuple_to_indextensor()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor"><code class="docutils literal notranslate"><span class="pre">CalipyTensor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.T"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.T</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.expand_to_dims"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.expand_to_dims()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.flatten"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.flatten()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.get_element"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.get_element()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.is_null"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.is_null</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.CalipyTensor.reorder"><code class="docutils literal notranslate"><span class="pre">CalipyTensor.reorder()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.IOIndexer"><code class="docutils literal notranslate"><span class="pre">IOIndexer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.IOIndexer.create_global_index"><code class="docutils literal notranslate"><span class="pre">IOIndexer.create_global_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.IOIndexer.create_local_index"><code class="docutils literal notranslate"><span class="pre">IOIndexer.create_local_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.IOIndexer.simple_subsample"><code class="docutils literal notranslate"><span class="pre">IOIndexer.simple_subsample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer"><code class="docutils literal notranslate"><span class="pre">TensorIndexer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.block_subsample"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.block_subsample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.create_block_subsample_indices"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.create_block_subsample_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.create_global_index"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.create_global_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.create_local_index"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.create_local_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.create_simple_subsample_indices"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.create_simple_subsample_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.expand_index"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.expand_index()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.reorder"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.reorder()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#calipy.core.tensor.TensorIndexer.simple_subsample"><code class="docutils literal notranslate"><span class="pre">TensorIndexer.simple_subsample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.broadcast_dims"><code class="docutils literal notranslate"><span class="pre">broadcast_dims()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.build_dim_supersequence"><code class="docutils literal notranslate"><span class="pre">build_dim_supersequence()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#calipy.core.tensor.preprocess_args"><code class="docutils literal notranslate"><span class="pre">preprocess_args()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data.html">calipy.core.data  (API)</a></li>
<li class="toctree-l2"><a class="reference internal" href="effects.html">calipy.core.effects  (API)</a></li>
<li class="toctree-l2"><a class="reference internal" href="dist.html">calipy.core.dist.distributions  (API)</a></li>
<li class="toctree-l2"><a class="reference internal" href="funs.html">calipy.core.funs  (API)</a></li>
<li class="toctree-l2"><a class="reference internal" href="primitives.html">calipy.core.primitives  (API)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example compilation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/quick_start/qs_examples_index.html">Quick-start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/engineering_geodesy/eg_examples_index.html">Engineering Geodesy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">calipy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">CaliPy API Reference</a></li>
      <li class="breadcrumb-item active">calipy.core.tensor  (API)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/tensor.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-calipy.core.tensor">
<span id="calipy-core-tensor-api"></span><span id="api-tensor"></span><h1>calipy.core.tensor  (API)<a class="headerlink" href="#module-calipy.core.tensor" title="Permalink to this heading"></a></h1>
<p>This module provides basic dimension aware tensor functionality needed for 
subsampling, indexing, attaching dimensions to tensors and other quality of
life features that allow tensors to keep and communicate extra structure.</p>
<dl class="simple">
<dt>The classes and functions are</dt><dd><dl class="simple">
<dt>CalipyIndex: Class of objects that can be used to index normal torch.tensors</dt><dd><p>and CalipyTensors or CalipyDistributions. Contains indextensors, tuples,
dims, names of the elements in the tensor and functionality for reducing
and expanding indices.</p>
</dd>
<dt>CalipyIndexer: Abstract class of objects that forms the basis for TensorIndexer</dt><dd><p>and DistributionIndexer and bundles indexing methods and attributes used
by both of these classes.</p>
</dd>
<dt>TensorIndexer: Class responsible for indexing tensors. Is attached directly</dt><dd><p>to CalipyTensors and takes over active duties like subsampling, keeping
track of the origin of subsampled data, and creating CalipyIndex objects
based on user demands.</p>
</dd>
</dl>
</dd>
</dl>
<p>The TensorIndexer and CalipyIndex classes provide basic functionality that is
used regularly in the context of defining basic effects and enabling primitives
that need to implement subsampling (like sampling or calling parameters.)</p>
<p>The script is meant solely for educational and illustrative purposes. Written by
Dr. Jemil Avers Butt, Atlas optimization GmbH, www.atlasoptimization.com.</p>
<dl class="py class">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">CalipyIndex</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_tensor_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class acting as a collection of infos on a specific index tensor collecting
basic index_tensor, index_tensor_tuple, and index_tensor_named. This class
represents a specific index tensor.</p>
<ul class="simple">
<li><p><cite>index_tensor.tensor</cite> is the original index tensor</p></li>
<li><p><cite>index_tensor.tuple</cite> can be used for indexing via <cite>data[tuple]</cite></p></li>
<li><p><cite>index_tensor.named</cite> can be used for dimension-specific operations</p></li>
</ul>
<dl class="py property">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.bound_dims">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bound_dims</span></span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.bound_dims" title="Permalink to this definition"></a></dt>
<dd><p>Returns the dims of ssi bound to the current actual sizes</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.expand_to_dims">
<span class="sig-name descname"><span class="pre">expand_to_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_sizes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.expand_to_dims" title="Permalink to this definition"></a></dt>
<dd><p>Expand the current index to include additional dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dims</strong> – A DimTuple containing the target dimensions.</p></li>
<li><p><strong>dim_sizes</strong> – A list containing sizes for the target dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new CalipyIndex instance with the expanded index tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.generate_index_name_dict">
<span class="sig-name descname"><span class="pre">generate_index_name_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.generate_index_name_dict" title="Permalink to this definition"></a></dt>
<dd><p>Generate a dictionary that maps indices to unique names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>global_index</strong> – CalipyIndex containing global index tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict mapping each elment of index tensor to unique name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.is_empty">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_empty</span></span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.is_empty" title="Permalink to this definition"></a></dt>
<dd><p>Indicates if no indexing is actually performed because e.g. indexed
quantity is a scalar and does not have dims. is_empty is passed to the 
CalipyTensor __getitem__ method to check if the full tensor is to be 
returned.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.is_null">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_null</span></span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.is_null" title="Permalink to this definition"></a></dt>
<dd><p>Indicates if the Index is null and will not perform any subsampling
just returning the orginal tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.is_reducible">
<span class="sig-name descname"><span class="pre">is_reducible</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims_to_keep</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.is_reducible" title="Permalink to this definition"></a></dt>
<dd><p>Determine if the index is reducible to the specified dimensions without loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dims_to_keep</strong> – DimTuple of CalipyDims to keep.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if reducible without loss, False otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.null">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.null" title="Permalink to this definition"></a></dt>
<dd><p>Construct a null index object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndex.reduce_to_dims">
<span class="sig-name descname"><span class="pre">reduce_to_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims_to_keep</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndex.reduce_to_dims" title="Permalink to this definition"></a></dt>
<dd><p>Reduce the current index to cover some subset of dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dims_to_keep</strong> – A DimTuple containing the target dimensions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new CalipyIndex instance with the reduced index tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndexer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">CalipyIndexer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndexer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Base class of an Indexer that implements methods for assigning dimensions
to specific slices of e.g. tensors or distributions. The methods and attributes
are rarely called directly; user interaction happens mostly with the subclasses
TensorIndexer and DistIndexer. Within these, functionality for subsampling,
batching, name generation etc are conretized. See those classes for examples
and specific implementation details.</p>
<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndexer.convert_indextensor_to_tuple">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convert_indextensor_to_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indextensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndexer.convert_indextensor_to_tuple" title="Permalink to this definition"></a></dt>
<dd><p>Converts an indextensor to an indextuple so that their actions for indexing
are equivalent in the sense that indexed tensor has entries from tensor indexed
by indextensor values: tensor[indextuple]  = tensor[indextensor.unbind(-1)].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indextensor</strong> – An indextensor containing an index at each location of value
in tensor</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An index tuple that can be used to index tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndexer.convert_slice_to_indextensor">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convert_slice_to_indextensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexslice_list</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndexer.convert_slice_to_indextensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts an indexslice_list to an indextensor so that their actions for indexing
are equivalent in the sense that sliced tensor has entries from tensor indexed
by indextensor values: tensor[indexslice_list]  = tensor[indextensor.unbind(-1)].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indexslice</strong> – An index slice that can be used to index tensors</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An indextensor containing an index at each location of value
in tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyIndexer.convert_tuple_to_indextensor">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convert_tuple_to_indextensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indextuple</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyIndexer.convert_tuple_to_indextensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts an indexstuple to an indextensor so that their actions for indexing
are equivalent in the sense that indexed tensor has entries from tensor indexed
by indextensor values: tensor[indextuple]  = tensor[indextensor.unbind(-1)].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indextuple</strong> – An index tuple that can be used to index tensors</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An indextensor containing an index at each location of value
in tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">CalipyTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tensor_noname'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class that wraps torch.Tensor objects and augments them with indexing operations
and dimension upkeep functionality, while referring most torch functions to
its wrapped torch. Tensor object. Can be sliced and indexed in the usual ways
which produces another CalipyTensor whose indexer is inherited.</p>
<dl class="simple">
<dt>Special creation rules for calipy tensors:</dt><dd><ol class="lowerroman simple">
<li><p>If tensor is None, dims must be None. Produces null object</p></li>
<li><p>If tensor exists and dims are None. Produces calipy tensor with generic dims</p></li>
<li><p>If calipy tensor is passed as input. Produces the same calipy tensor</p></li>
<li><p>If calipy tensor is passed as input and some dims. Produces new calipy
tensor with new dims.</p></li>
<li><p>It tensor exists and dims exist, produce regular calipy tensor.</p></li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – The tensor which should be embedded into CalipyTensor</p></li>
<li><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple containing the dimensions of the tensor or None</p></li>
<li><p><strong>name</strong> (<em>string</em>) – A name for the CalipyTensor, useful for keeping track of derived CalipyTensor’s.
Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of CalipyTensor containing functionality for dimension
upkeep, indexing, and function call referral.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.CalipyTensor" title="calipy.core.tensor.CalipyTensor">CalipyTensor</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and definitions</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">calipy.core.tensor</span> <span class="kn">import</span> <span class="n">CalipyTensor</span><span class="p">,</span> <span class="n">TensorIndexer</span><span class="p">,</span> <span class="n">CalipyIndex</span>
<span class="kn">from</span> <span class="nn">calipy.core.utils</span> <span class="kn">import</span> <span class="n">dim_assignment</span>
<span class="kn">from</span> <span class="nn">calipy.core.data</span> <span class="kn">import</span> <span class="n">DataTuple</span>

<span class="c1"># Create CalipyTensors -----------------------------------------------</span>
<span class="c1">#</span>
<span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_A_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">batch_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1_A&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_A&#39;</span><span class="p">])</span>
<span class="n">event_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1_A&#39;</span><span class="p">])</span>
<span class="n">data_dims_A</span> <span class="o">=</span> <span class="n">batch_dims_A</span> <span class="o">+</span> <span class="n">event_dims_A</span>
<span class="n">data_A_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_A_torch</span><span class="p">,</span> <span class="n">data_dims_A</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;data_A&#39;</span><span class="p">)</span>

<span class="c1"># Confirm that subsampling works as intended</span>
<span class="n">subtensor_1</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span>  <span class="c1"># identical to next line</span>
<span class="n">subtensor_1</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span>
<span class="n">subtensor_1</span><span class="o">.</span><span class="n">dims</span> <span class="o">==</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">dims</span>
<span class="k">assert</span><span class="p">((</span><span class="n">subtensor_1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
<span class="c1"># subsample has global_index that can be used for subsampling on tensors</span>
<span class="c1"># and on CalipyTensors</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_A_cp</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">subtensor_1</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span> 
        <span class="o">-</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
<span class="k">assert</span><span class="p">(((</span><span class="n">data_A_cp</span><span class="p">[</span><span class="n">subtensor_1</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span><span class="p">]</span> 
        <span class="o">-</span> <span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>

<span class="c1"># When using an integer, dims are kept; i.e. singleton dims are not reduced</span>
<span class="n">subtensor_2</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span>
<span class="k">assert</span><span class="p">((</span><span class="n">subtensor_2</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>

<span class="c1"># Indexing of CalipyTensors via int, tuple, slice, and CalipyIndex</span>
<span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span>
<span class="n">local_index</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">data_A_cp</span><span class="p">[</span><span class="n">local_index</span><span class="p">]</span>
<span class="c1"># During addressing, appropriate indexers are built</span>
<span class="n">data_A_cp</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span>
<span class="n">data_A_cp</span><span class="p">[</span><span class="n">local_index</span><span class="p">]</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span>

<span class="c1"># CalipyTensors work well even when some dims are empty</span>
<span class="c1"># Set up data and dimensions</span>
<span class="n">data_0dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([])</span>
<span class="n">data_1dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">])</span>
<span class="n">data_2dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">batch_dim</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd&#39;</span><span class="p">])</span>
<span class="n">event_dim</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;ed&#39;</span><span class="p">])</span>
<span class="n">empty_dim</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;empty&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[])</span>

<span class="n">data_0dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_0dim</span><span class="p">,</span> <span class="n">empty_dim</span><span class="p">)</span>
<span class="n">data_1dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_1dim</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">)</span>
<span class="n">data_1dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_1dim</span><span class="p">,</span> <span class="n">batch_dim</span> <span class="o">+</span> <span class="n">empty_dim</span><span class="p">)</span>
<span class="n">data_1dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_1dim</span><span class="p">,</span> <span class="n">empty_dim</span> <span class="o">+</span> <span class="n">batch_dim</span> <span class="o">+</span> <span class="n">empty_dim</span><span class="p">)</span>

<span class="n">data_2dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_2dim</span><span class="p">,</span> <span class="n">batch_dim</span> <span class="o">+</span> <span class="n">event_dim</span><span class="p">)</span>
<span class="n">data_2dim_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_2dim</span><span class="p">,</span> <span class="n">batch_dim</span> <span class="o">+</span> <span class="n">empty_dim</span> <span class="o">+</span> <span class="n">event_dim</span><span class="p">)</span>

<span class="c1"># Indexing a scalar with an empty index just returns the scalar</span>
<span class="n">data_0dim_cp</span><span class="o">.</span><span class="n">indexer</span>
<span class="n">zerodim_index</span> <span class="o">=</span> <span class="n">data_0dim_cp</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">zerodim_index</span><span class="o">.</span><span class="n">is_empty</span>
<span class="n">data_0dim_cp</span><span class="p">[</span><span class="n">zerodim_index</span><span class="p">]</span>

<span class="c1"># # These produce errors or warnings as they should.</span>
<span class="c1"># data_0dim_cp = CalipyTensor(data_0dim, batch_dim) # Trying to assign nonempty dim to scalar</span>
<span class="c1"># data_1dim_cp = CalipyTensor(data_1dim, empty_dim) # Trying to assign empty dim to vector</span>
<span class="c1"># data_2dim_cp = CalipyTensor(data_2dim, batch_dim + empty_dim) # Trying to assign empty dim to vector</span>


<span class="c1"># CalipyTensor / DataTuple interaction ---------------------------------</span>
<span class="c1">#</span>
<span class="c1"># DataTuple and CalipyTensor interact well: In the following we showcase</span>
<span class="c1"># that a DataTuple of CalipyTensors can be subsampled by providing a</span>
<span class="c1"># DataTuple of CalipyIndexes or a single CalipyIndex that is automatically</span>
<span class="c1"># distributed over the CalipyTensors for indexing.</span>

<span class="c1"># Set up DataTuple of CalipyTensors</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">])</span>
<span class="n">event_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1_A&#39;</span><span class="p">,</span> <span class="s1">&#39;ed_2_A&#39;</span><span class="p">])</span>
<span class="n">data_dims_A</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims_A</span>
<span class="n">event_dims_B</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1_B&#39;</span><span class="p">])</span>
<span class="n">data_dims_B</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims_B</span>
<span class="n">data_A_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">data_A_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_A_torch</span><span class="p">,</span> <span class="n">data_dims_A</span><span class="p">,</span> <span class="s1">&#39;data_A&#39;</span><span class="p">)</span>
<span class="n">data_B_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_B_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_B_torch</span><span class="p">,</span> <span class="n">data_dims_B</span><span class="p">,</span> <span class="s1">&#39;data_B&#39;</span><span class="p">)</span>

<span class="n">data_AB_tuple</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">([</span><span class="s1">&#39;data_A_cp&#39;</span><span class="p">,</span> <span class="s1">&#39;data_B_cp&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">data_A_cp</span><span class="p">,</span> <span class="n">data_B_cp</span><span class="p">])</span>


<span class="c1"># Subsampling functionality -------------------------------------------</span>
<span class="c1">#</span>
<span class="c1"># subsample the data individually</span>
<span class="n">data_AB_subindices</span> <span class="o">=</span> <span class="n">TensorIndexer</span><span class="o">.</span><span class="n">create_simple_subsample_indices</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data_AB_subindex</span> <span class="o">=</span> <span class="n">data_AB_subindices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">data_A_subindex</span> <span class="o">=</span> <span class="n">data_AB_subindex</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_A</span><span class="p">,</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data_B_subindex</span> <span class="o">=</span> <span class="n">data_AB_subindex</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_B</span><span class="p">,</span> <span class="n">data_B_cp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data_AB_sub_1</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">([</span><span class="s1">&#39;data_A_cp_sub&#39;</span><span class="p">,</span> <span class="s1">&#39;data_B_cp_sub&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">data_A_cp</span><span class="p">[</span><span class="n">data_A_subindex</span><span class="p">],</span> <span class="n">data_B_cp</span><span class="p">[</span><span class="n">data_B_subindex</span><span class="p">]])</span>

<span class="c1"># Use subsampling functionality for DataTuples, either by passing a DataTuple of</span>
<span class="c1"># CalipyIndex or a single CalipyIndex that is broadcasted</span>
<span class="n">data_AB_subindex_tuple</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">([</span><span class="s1">&#39;data_A_cp&#39;</span><span class="p">,</span> <span class="s1">&#39;data_B_cp&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">data_A_subindex</span><span class="p">,</span> <span class="n">data_B_subindex</span><span class="p">])</span>
<span class="n">data_AB_sub_2</span> <span class="o">=</span> <span class="n">data_AB_tuple</span><span class="o">.</span><span class="n">subsample</span><span class="p">(</span><span class="n">data_AB_subindex_tuple</span><span class="p">)</span>
<span class="n">data_AB_sub_3</span> <span class="o">=</span> <span class="n">data_AB_tuple</span><span class="o">.</span><span class="n">subsample</span><span class="p">(</span><span class="n">data_AB_subindex</span><span class="p">)</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_AB_sub_1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_AB_sub_2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_AB_sub_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_AB_sub_3</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>


<span class="c1"># Expansion and reordering -------------------------------------------</span>
<span class="c1">#</span>
<span class="c1"># Expand a tensor by copying it among some dimensions.</span>
<span class="n">data_dims_A</span> <span class="o">=</span> <span class="n">data_dims_A</span><span class="o">.</span><span class="n">bind</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">data_dims_B</span> <span class="o">=</span> <span class="n">data_dims_B</span><span class="o">.</span><span class="n">bind</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_dims_expanded</span> <span class="o">=</span> <span class="n">data_dims_A</span> <span class="o">+</span> <span class="n">data_dims_B</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">data_A_expanded_cp</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_expanded</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_A_expanded_cp</span><span class="p">[:,:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
<span class="c1"># Ordering of dims is also ordering of result</span>
<span class="n">data_dims_expanded_reordered</span> <span class="o">=</span> <span class="n">data_dims_A</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">data_dims_A</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">data_dims_B</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">data_A_expanded_reordered_cp</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_expanded_reordered</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_A_expanded_reordered_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span>
        <span class="n">data_A_expanded_cp</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>

<span class="c1"># There also exists a CalipyTensor.reorder(dims) method</span>
<span class="n">data_dims_A_reordered</span> <span class="o">=</span> <span class="n">event_dims_A</span> <span class="o">+</span> <span class="n">batch_dims</span>
<span class="n">data_A_reordered_cp</span> <span class="o">=</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">data_dims_A_reordered</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_A_reordered_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">data_A_cp</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
<span class="k">assert</span><span class="p">(</span><span class="n">data_A_reordered_cp</span><span class="o">.</span><span class="n">dims</span> <span class="o">==</span> <span class="n">data_dims_A_reordered</span><span class="p">)</span>


<span class="c1"># Null object functionality -------------------------------------------</span>

<span class="c1"># CalipyTensors and CalipyIndex also work with None inputs to produce Null objects</span>
<span class="c1"># Create data for initialization</span>
<span class="n">tensor_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd&#39;</span><span class="p">,</span> <span class="s1">&#39;ed&#39;</span><span class="p">])</span>
<span class="n">tensor_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">tensor_dims</span><span class="p">)</span> 
<span class="n">tensor_none</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">index_full</span> <span class="o">=</span> <span class="n">tensor_cp</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">index_none</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># ii) Create and investigate null CalipyIndex</span>
<span class="n">CI_none</span> <span class="o">=</span> <span class="n">CalipyIndex</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">CI_none</span><span class="p">)</span>
<span class="n">CI_expanded</span> <span class="o">=</span> <span class="n">CI_none</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">tensor_dims</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Passing a null index to CalipyTensor returns the orginal tensor.</span>
<span class="n">tensor_cp</span><span class="p">[</span><span class="n">CI_none</span><span class="p">]</span>
<span class="n">tensor_cp</span><span class="p">[</span><span class="n">CI_expanded</span><span class="p">]</span>
<span class="c1"># The following errors out, as intended: </span>
<span class="c1">#   CalipyIndex(torch.ones([1]), index_tensor_dims = None)</span>

<span class="c1"># iii) Create and investigate null CalipyTensor</span>
<span class="n">CT_none</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="n">CT_none</span>
<span class="n">CT_none</span><span class="p">[</span><span class="n">CI_none</span><span class="p">]</span> 
<span class="n">CT_none</span><span class="p">[</span><span class="n">CI_expanded</span><span class="p">]</span>

<span class="n">tensor_dims_bound</span> <span class="o">=</span> <span class="n">tensor_dims</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">tensor_cp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">CT_expanded</span> <span class="o">=</span> <span class="n">CT_none</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">tensor_dims_bound</span><span class="p">)</span>
<span class="c1"># The following errors out, as intended: </span>
<span class="c1">#   CalipyIndex(torch.ones([1]), index_tensor_dims = None)</span>


<span class="c1"># Special creation rules for calipy tensors ---------------------------</span>
<span class="c1">#   i) If tensor is None, dims must be None. Produces null object</span>
<span class="c1">#   ii) If tensor exists and dims are None. Produces calipy tensor with generic dims</span>
<span class="c1">#   iii) If calipy tensor is passed as input. Produces the same calipy tensor</span>
<span class="c1">#   iv) If calipy tensor is passd as input and some dims. Produces new calipy tensor with new dims.</span>

<span class="n">tensor_A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd&#39;</span><span class="p">,</span> <span class="s1">&#39;ed&#39;</span><span class="p">])</span>
<span class="n">dims_A_alt</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd_alt&#39;</span><span class="p">,</span> <span class="s1">&#39;ed_alt&#39;</span><span class="p">])</span>
<span class="n">tensor_A_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">tensor_A</span><span class="p">,</span> <span class="n">dims_A</span><span class="p">)</span>

<span class="n">tensor_cp_None</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="n">tensor_cp_default</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">tensor_A</span><span class="p">)</span>
<span class="n">tensor_cp_idempotent</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">tensor_A_cp</span><span class="p">)</span>
<span class="n">tensor_cp_alt</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">tensor_A_cp</span><span class="p">,</span> <span class="n">dims_A_alt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor_cp_alt</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.T">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">T</span></span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.T" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.expand_to_dims">
<span class="sig-name descname"><span class="pre">expand_to_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.expand_to_dims" title="Permalink to this definition"></a></dt>
<dd><p>Expands the current CalipyTensor to another CalipyTensor with dims
specified in argument dims. Returns a CalipyTensor with dims dims that
consists of copies of self where expansion is necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple instance that contains the dims of the current
CalipyTensor and prescribes the dims of the expanded CalipyTensor</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of CalipyTensor expanded to match dims.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.CalipyTensor" title="calipy.core.tensor.CalipyTensor">CalipyTensor</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">])</span>
<span class="n">event_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_dims</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_torch</span><span class="p">,</span> <span class="n">data_dims</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>

<span class="n">batch_dims_expanded</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">data_dims_expanded</span> <span class="o">=</span> <span class="n">batch_dims_expanded</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">data_expanded_cp</span> <span class="o">=</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_expanded</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_expanded_cp</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.flatten">
<span class="sig-name descname"><span class="pre">flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims_to_flatten</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_flat_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'flat_dim'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.flatten" title="Permalink to this definition"></a></dt>
<dd><p>Flattens the current CalipyTensor to another CalipyTensor by collapsing
the dims dims_to_flatten towards a new dim with name name_dim_flat.
Procedure consists of reordering followed by reshaping and repackaging
into a new CalipyTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dims_to_flatten</strong> (<em>DimTuple</em>) – A DimTuple instance that contains some dims of 
the current CalipyTensor that are to be flattened.</p></li>
<li><p><strong>name_flat_dim</strong> – A string providing the name of the flattened dim 
that will replace the collapsed dims.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of CalipyTensor reordered to match dims.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.CalipyTensor" title="calipy.core.tensor.CalipyTensor">CalipyTensor</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and definitions</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">calipy.core.utils</span> <span class="kn">import</span> <span class="n">dim_assignment</span>
<span class="kn">from</span> <span class="nn">calipy.core.tensor</span> <span class="kn">import</span> <span class="n">CalipyTensor</span>

<span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">event_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_dims</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_torch</span><span class="p">,</span> <span class="n">data_dims</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>

<span class="n">data_flattened_cp</span> <span class="o">=</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_flattened_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.get_element">
<span class="sig-name descname"><span class="pre">get_element</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.get_element" title="Permalink to this definition"></a></dt>
<dd><p>Access the tensor at positions indices in dims dims of self and return it.
Returns a CalipyTensor with the same dims as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple instance that represents the dims in which indexing
should be performed</p></li>
<li><p><strong>indices</strong> (<em>list</em><em> of </em><em>int</em>) – A list containing integers providing where to access 
the corresponding dimensions. match between dims and indices is done
via ordering</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of CalipyTensor containing the one element of self</p>
</dd>
</dl>
<p>where [dims = indices ,…].
:rtype: CalipyTensor</p>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and definitions</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">calipy.core.tensor</span> <span class="kn">import</span> <span class="n">CalipyTensor</span>
<span class="kn">from</span> <span class="nn">calipy.core.utils</span> <span class="kn">import</span> <span class="n">dim_assignment</span>

<span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">event_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_dims</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_torch</span><span class="p">,</span> <span class="n">data_dims</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>

<span class="c1"># Access the single element where batch_dim &#39;bd_1&#39; has the value 5</span>
<span class="n">data_cp_element_1</span> <span class="o">=</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">get_element</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_cp_element_1</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>

<span class="c1"># Access the single element where batch_dims has the value [5,2]</span>
<span class="n">data_cp_element_2</span> <span class="o">=</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">get_element</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_cp_element_2</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.is_null">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_null</span></span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.is_null" title="Permalink to this definition"></a></dt>
<dd><p>Indicates if the Index is null and will not perform any subsampling
just returning the orginal tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.CalipyTensor.reorder">
<span class="sig-name descname"><span class="pre">reorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.CalipyTensor.reorder" title="Permalink to this definition"></a></dt>
<dd><p>Reorders the current CalipyTensor to another CalipyTensor with dims
ordered as specified in argument dims.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple instance that contains the dims of the current
CalipyTensor and prescribes the dims of the reordered CalipyTensor</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of CalipyTensor reordered to match dims.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.CalipyTensor" title="calipy.core.tensor.CalipyTensor">CalipyTensor</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">event_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1&#39;</span><span class="p">],</span> <span class="n">dim_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_dims</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_torch</span><span class="p">,</span> <span class="n">data_dims</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>

<span class="n">data_dims_reordered</span> <span class="o">=</span> <span class="n">event_dims</span> <span class="o">+</span> <span class="n">batch_dims</span>
<span class="n">data_reordered_cp</span> <span class="o">=</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">data_dims_reordered</span><span class="p">)</span>
<span class="k">assert</span><span class="p">((</span><span class="n">data_reordered_cp</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">data_cp</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
<span class="k">assert</span><span class="p">(</span><span class="n">data_reordered_cp</span><span class="o">.</span><span class="n">dims</span> <span class="o">==</span> <span class="n">data_dims_reordered</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="calipy.core.tensor.IOIndexer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">IOIndexer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">calipy_io</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.IOIndexer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#calipy.core.tensor.CalipyIndexer" title="calipy.core.tensor.CalipyIndexer"><code class="xref py py-class docutils literal notranslate"><span class="pre">CalipyIndexer</span></code></a></p>
<p>Class to handle indexing operations for CalipyIO objects, including creating
local and global indices, managing subsampling, and generating named dictionaries
for indexing purposes. Takes as input a CalipyIO object and a DimTuple object
and creates a CalipyIndexer object that can be used to produce indices, bind
dimensions, order the calipy_io and similar other support functionality.
Indexing is performed over the calipy_list elements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>calipy_io</strong> (<a class="reference internal" href="data.html#calipy.core.data.CalipyIO" title="calipy.core.data.CalipyIO"><em>CalipyIO</em></a>) – The CalipyIO object for which the indexer is to be constructed</p></li>
<li><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple containing the dimensions of the tensor</p></li>
<li><p><strong>name</strong> (<em>string</em>) – A name for the indexer, useful for keeping track of subservient indexers.
Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of TensorIndexer containing functionality for indexing the
input tensor including subbatching, naming, index tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.TensorIndexer" title="calipy.core.tensor.TensorIndexer">TensorIndexer</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_A_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">batch_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1_A&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_A&#39;</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.IOIndexer.create_global_index">
<span class="sig-name descname"><span class="pre">create_global_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subsample_indextensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_source_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.IOIndexer.create_global_index" title="Permalink to this definition"></a></dt>
<dd><p>Create a global CalipyIndex object enumerating all possible indices for all the dims. The
indices global_index_tensor are chosen such that they can be used to access the data
in data_source with name data_source_name via self.tensor  = data_source[global_index_tensor_tuple]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subsample_indextensor</strong> – An index tensor that enumerates for all the entries of
self.tensor which index needs to be used to access it in some global dataset.</p></li>
<li><p><strong>data_source_name</strong> – A string serving as info to record which object the global indices are indexing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A CalipyIndex object global index containing indexing data that
describes how the tensor is related to the superpopulation it has been
sampled from.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.IOIndexer.create_local_index">
<span class="sig-name descname"><span class="pre">create_local_index</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.IOIndexer.create_local_index" title="Permalink to this definition"></a></dt>
<dd><p>Create a local index tensor enumerating all indices for the list calipy_list
inside of the CalipyIO object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns CalipyIndex containing torch tensors with indices
representing all list indices.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.IOIndexer.simple_subsample">
<span class="sig-name descname"><span class="pre">simple_subsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.IOIndexer.simple_subsample" title="Permalink to this definition"></a></dt>
<dd><p>Generate indices for subbatching across a single batch dimension and 
extract the subbatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_dim</strong> – Element of DimTuple (typically CalipyDim) along which
subbatching happens.</p></li>
<li><p><strong>subsample_size</strong> – Single size determining length of batches to create.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of tensors and CalipyIndex representing the subbatches.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">TensorIndexer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#calipy.core.tensor.CalipyIndexer" title="calipy.core.tensor.CalipyIndexer"><code class="xref py py-class docutils literal notranslate"><span class="pre">CalipyIndexer</span></code></a></p>
<p>Class to handle indexing operations for observations, including creating local
and global indices, managing subsampling, and generating named dictionaries
for indexing purposes. Takes as input a tensor and a DimTuple object and creates
a CalipyIndexer object that can be used to produce indices, bind dimensions, 
order the tensor and similar other support functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – The tensor for which the indexer is to be constructed</p></li>
<li><p><strong>dims</strong> (<em>DimTuple</em>) – A DimTuple containing the dimensions of the tensor</p></li>
<li><p><strong>name</strong> (<em>string</em>) – A name for the indexer, useful for keeping track of subservient indexers.
Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of TensorIndexer containing functionality for indexing the
input tensor including subbatching, naming, index tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#calipy.core.tensor.TensorIndexer" title="calipy.core.tensor.TensorIndexer">TensorIndexer</a></p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DimTuples and tensors</span>
<span class="n">data_A_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">batch_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1_A&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_A&#39;</span><span class="p">])</span>
<span class="n">event_dims_A</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1_A&#39;</span><span class="p">])</span>
<span class="n">data_dims_A</span> <span class="o">=</span> <span class="n">batch_dims_A</span> <span class="o">+</span> <span class="n">event_dims_A</span>


<span class="c1"># Evoke indexer</span>
<span class="n">data_A</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_A_torch</span><span class="p">,</span> <span class="n">data_dims_A</span><span class="p">,</span> <span class="s1">&#39;data_A&#39;</span><span class="p">)</span>
<span class="n">indexer</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">indexer</span>
<span class="nb">print</span><span class="p">(</span><span class="n">indexer</span><span class="p">)</span>

<span class="c1"># Indexer contains the tensor, its dims, and bound tensor</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_dims</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_dims</span><span class="o">.</span><span class="vm">__class__</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_dims</span><span class="o">.</span><span class="n">sizes</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_torchdims</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_torchdims</span><span class="o">.</span><span class="vm">__class__</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_torchdims</span><span class="o">.</span><span class="n">sizes</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">tensor_named</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">index_dim</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">index_tensor_dims</span>

<span class="c1"># Functionality indexer</span>
<span class="n">attr_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">attr</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">indexer</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;__&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">attr</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attr_list</span><span class="p">)</span>

<span class="c1"># Functionality index</span>
<span class="n">local_index</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">local_index</span>
<span class="n">local_index</span><span class="o">.</span><span class="n">dims</span>
<span class="n">local_index</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
<span class="n">local_index</span><span class="o">.</span><span class="n">index_name_dict</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_A</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">local_index</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span> <span class="o">==</span> <span class="n">data_A</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_A</span><span class="p">[</span><span class="n">local_index</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_A</span><span class="p">)</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>


<span class="c1"># Reordering and indexing by DimTuple</span>
<span class="n">reordered_dims</span> <span class="o">=</span> <span class="n">DimTuple</span><span class="p">((</span><span class="n">data_dims_A</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_dims_A</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data_dims_A</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">data_A_reordered</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">reordered_dims</span><span class="p">)</span>
<span class="n">data_tdims_A</span> <span class="o">=</span> <span class="n">data_dims_A</span><span class="o">.</span><span class="n">build_torchdims</span><span class="p">()</span>
<span class="n">data_tdims_A_reordered</span> <span class="o">=</span> <span class="n">data_tdims_A</span><span class="p">[</span><span class="n">reordered_dims</span><span class="p">]</span>
<span class="n">data_A_named_tensor</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">data_tdims_A</span><span class="p">]</span>
<span class="n">data_A_named_tensor_reordered</span> <span class="o">=</span> <span class="n">data_A_reordered</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">data_tdims_A_reordered</span><span class="p">]</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_A_named_tensor</span><span class="o">.</span><span class="n">order</span><span class="p">(</span><span class="o">*</span><span class="n">data_tdims_A</span><span class="p">)</span> <span class="o">==</span> <span class="n">data_A_named_tensor_reordered</span><span class="o">.</span><span class="n">order</span><span class="p">(</span><span class="o">*</span><span class="n">data_tdims_A</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># Subbatching along one or multiple dims</span>
<span class="n">subsamples</span><span class="p">,</span> <span class="n">subsample_indices</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">simple_subsample</span><span class="p">(</span><span class="n">batch_dims_A</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape subsamples = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">subsample</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">subsample</span> <span class="ow">in</span> <span class="n">subsamples</span><span class="p">]))</span>
<span class="n">block_batch_dims_A</span> <span class="o">=</span> <span class="n">batch_dims_A</span>
<span class="n">block_subsample_sizes_A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">block_subsamples</span><span class="p">,</span> <span class="n">block_subsample_indices</span> <span class="o">=</span> <span class="n">data_A</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">block_subsample</span><span class="p">(</span><span class="n">block_batch_dims_A</span><span class="p">,</span> <span class="n">block_subsample_sizes_A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape block subsamples = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">subsample</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">subsample</span> <span class="ow">in</span> <span class="n">block_subsamples</span><span class="p">]))</span>

<span class="c1"># Inheritance - by construction</span>
<span class="c1"># Suppose we got data_C as a subset of data_B with derived ssi CalipyIndex and</span>
<span class="c1"># now want to index data_C with proper names and references</span>
<span class="c1">#   1. generate data_B</span>
<span class="n">batch_dims_B</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd_1_B&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_B&#39;</span><span class="p">])</span>
<span class="n">event_dims_B</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;ed_1_B&#39;</span><span class="p">])</span>
<span class="n">data_dims_B</span> <span class="o">=</span> <span class="n">batch_dims_B</span> <span class="o">+</span> <span class="n">event_dims_B</span>
<span class="n">data_B_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">data_B</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_B_torch</span><span class="p">,</span> <span class="n">data_dims_B</span><span class="p">,</span> <span class="s1">&#39;data_B&#39;</span><span class="p">)</span>

<span class="c1">#   2. subsample data_C from data_B</span>
<span class="n">block_data_C</span><span class="p">,</span> <span class="n">block_indices_C</span> <span class="o">=</span> <span class="n">data_B</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">block_subsample</span><span class="p">(</span><span class="n">batch_dims_B</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">block_nr</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">data_C</span> <span class="o">=</span> <span class="n">block_data_C</span><span class="p">[</span><span class="n">block_nr</span><span class="p">]</span>
<span class="n">block_index_C</span> <span class="o">=</span> <span class="n">block_indices_C</span><span class="p">[</span><span class="n">block_nr</span><span class="p">]</span>

<span class="c1">#   3. subsampling has created an indexer for data_C</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span><span class="o">.</span><span class="n">tensor</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span><span class="o">.</span><span class="n">tensor</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span><span class="o">.</span><span class="n">index_name_dict</span>
<span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">data_source_name</span>

<span class="n">data_C_local_index</span> <span class="o">=</span> <span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">local_index</span>
<span class="n">data_C_global_index</span> <span class="o">=</span> <span class="n">data_C</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_C</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">data_C_local_index</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span> <span class="o">==</span> <span class="n">data_B</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">data_C_global_index</span><span class="o">.</span><span class="n">tuple</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_C</span><span class="p">[</span><span class="n">data_C_local_index</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_B</span><span class="p">[</span><span class="n">data_C_global_index</span><span class="p">])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># Inheritance - by declaration</span>
<span class="c1"># If data comes out of some external subsampling and only the corresponding indextensors</span>
<span class="c1"># are known, the calipy_indexer can be evoked manually.</span>
<span class="n">data_D_torch</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">data_C</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="n">index_tensor_D</span> <span class="o">=</span> <span class="n">block_index_C</span><span class="o">.</span><span class="n">tensor</span>

<span class="n">data_D</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_D_torch</span><span class="p">,</span> <span class="n">data_dims_B</span><span class="p">,</span> <span class="s1">&#39;data_D&#39;</span><span class="p">)</span>
<span class="n">data_D</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">create_global_index</span><span class="p">(</span><span class="n">index_tensor_D</span><span class="p">,</span> <span class="s1">&#39;from_data_D&#39;</span><span class="p">)</span>
<span class="n">data_D_global_index</span> <span class="o">=</span> <span class="n">data_D</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">global_index</span>

<span class="k">assert</span> <span class="p">(</span><span class="n">data_D</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">data_B</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">data_D_global_index</span><span class="o">.</span><span class="n">tuple</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_D</span> <span class="o">-</span> <span class="n">data_B</span><span class="p">[</span><span class="n">data_D_global_index</span><span class="p">])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># Alternative way of calling via DataTuples</span>
<span class="n">data_E_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,[</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">batch_dims_E</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1_E&#39;</span><span class="p">])</span>
<span class="n">event_dims_E</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1_E&#39;</span><span class="p">])</span>
<span class="n">data_dims_E</span> <span class="o">=</span> <span class="n">batch_dims_E</span> <span class="o">+</span> <span class="n">event_dims_E</span>

<span class="n">data_names_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;data_A&#39;</span><span class="p">,</span> <span class="s1">&#39;data_E&#39;</span><span class="p">]</span>
<span class="n">data_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_A_torch</span><span class="p">,</span> <span class="n">data_E_torch</span><span class="p">]</span>
<span class="n">data_datatuple_torch</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">(</span><span class="n">data_names_list</span><span class="p">,</span> <span class="n">data_list</span><span class="p">)</span>

<span class="n">batch_dims_datatuple</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">(</span><span class="n">data_names_list</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_dims_A</span><span class="p">,</span> <span class="n">batch_dims_E</span><span class="p">])</span>
<span class="n">event_dims_datatuple</span> <span class="o">=</span> <span class="n">DataTuple</span><span class="p">(</span><span class="n">data_names_list</span><span class="p">,</span> <span class="p">[</span><span class="n">event_dims_A</span><span class="p">,</span> <span class="n">event_dims_E</span><span class="p">])</span>
<span class="n">data_dims_datatuple</span> <span class="o">=</span> <span class="n">batch_dims_datatuple</span> <span class="o">+</span> <span class="n">event_dims_datatuple</span>

<span class="n">data_datatuple</span> <span class="o">=</span> <span class="n">data_datatuple_torch</span><span class="o">.</span><span class="n">calipytensor_construct</span><span class="p">(</span><span class="n">data_dims_datatuple</span><span class="p">)</span>
<span class="n">data_datatuple</span><span class="p">[</span><span class="s1">&#39;data_A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">indexer</span>


<span class="c1"># Functionality for creating indices with TensorIndexer class methods</span>
<span class="c1"># It is possible to create subsample_indices even when no tensor is given</span>
<span class="c1"># simply by calling the class method TensorIndexer.create_block_subsample_indices</span>
<span class="c1"># or TensorIndexer.create_simple_subsample_indices and providing the </span>
<span class="c1"># appropriate size specifications.         </span>
<span class="c1"># i) Create the dims (with unspecified size so no conflict later when subbatching)</span>
<span class="n">batch_dims_FG</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;bd_1_FG&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_FG&#39;</span><span class="p">])</span>
<span class="n">event_dims_F</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;ed_1_F&#39;</span><span class="p">,</span> <span class="s1">&#39;ed_2_F&#39;</span><span class="p">])</span>
<span class="n">event_dims_G</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;ed_1_G&#39;</span><span class="p">])</span>
<span class="n">data_dims_F</span> <span class="o">=</span> <span class="n">batch_dims_FG</span> <span class="o">+</span> <span class="n">event_dims_F</span>
<span class="n">data_dims_G</span> <span class="o">=</span> <span class="n">batch_dims_FG</span> <span class="o">+</span> <span class="n">event_dims_G</span>

<span class="c1"># ii) Sizes</span>
<span class="n">batch_dims_FG_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
<span class="n">event_dims_F_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="n">event_dims_G_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
<span class="n">data_dims_F_sizes</span> <span class="o">=</span> <span class="n">batch_dims_FG_sizes</span> <span class="o">+</span> <span class="n">event_dims_F_sizes</span>
<span class="n">data_dims_G_sizes</span> <span class="o">=</span> <span class="n">batch_dims_FG_sizes</span> <span class="o">+</span> <span class="n">event_dims_G_sizes</span>

<span class="c1"># iii) Then create the data</span>
<span class="n">data_F_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_dims_F_sizes</span><span class="p">)</span>
<span class="n">data_F</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_F_torch</span><span class="p">,</span> <span class="n">data_dims_F</span><span class="p">,</span> <span class="s1">&#39;data_F&#39;</span><span class="p">)</span>
<span class="n">data_G_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_dims_G_sizes</span><span class="p">)</span>
<span class="n">data_G</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">data_G_torch</span><span class="p">,</span> <span class="n">data_dims_G</span><span class="p">,</span> <span class="s1">&#39;data_G&#39;</span><span class="p">)</span>

<span class="c1"># iv) Create and expand the reduced_index</span>
<span class="n">indices_reduced</span> <span class="o">=</span> <span class="n">TensorIndexer</span><span class="o">.</span><span class="n">create_block_subsample_indices</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">,</span> <span class="n">batch_dims_FG_sizes</span><span class="p">,</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">index_reduced</span> <span class="o">=</span> <span class="n">indices_reduced</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Functionality for expanding, reducing, and reordering indices</span>
<span class="c1"># Indices like the ones above can be used flexibly by expanding them to</span>
<span class="c1"># fit tensors with various dimensions. They can also be changed w.r.t </span>
<span class="c1"># their order.</span>

<span class="c1"># i) Expand index to fit data_F and data_G</span>
<span class="n">index_expanded_F</span> <span class="o">=</span> <span class="n">index_reduced</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_F</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span> <span class="o">+</span> <span class="n">event_dims_F_sizes</span><span class="p">)</span>
<span class="n">index_expanded_G</span> <span class="o">=</span> <span class="n">index_reduced</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_G</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span> <span class="o">+</span> <span class="n">event_dims_G_sizes</span><span class="p">)</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_F</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">index_expanded_F</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span> <span class="o">==</span> <span class="n">data_F</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">],</span> <span class="p">:,:])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_F</span><span class="p">[</span><span class="n">index_expanded_F</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_F</span><span class="p">[</span><span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">],</span> <span class="p">:,:])</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># ii) Reordering is done by passing in a differently ordered DimTuple</span>
<span class="n">data_dims_F_reordered</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">([</span><span class="s1">&#39;ed_2_F&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_2_FG&#39;</span><span class="p">,</span> <span class="s1">&#39;ed_1_F&#39;</span><span class="p">,</span> <span class="s1">&#39;bd_1_FG&#39;</span><span class="p">])</span>
<span class="n">data_dims_F_reordered_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">index_expanded_F_reordered</span> <span class="o">=</span> <span class="n">index_reduced</span><span class="o">.</span><span class="n">expand_to_dims</span><span class="p">(</span><span class="n">data_dims_F_reordered</span><span class="p">,</span> <span class="n">data_dims_F_reordered_sizes</span><span class="p">)</span>
<span class="n">data_F_reordered</span> <span class="o">=</span> <span class="n">data_F</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">data_dims_F_reordered</span><span class="p">)</span>
<span class="n">data_F_subsample</span> <span class="o">=</span> <span class="n">data_F</span><span class="p">[</span><span class="n">index_expanded_F</span><span class="p">]</span>
<span class="n">data_F_reordered_subsample</span> <span class="o">=</span> <span class="n">data_F_reordered</span><span class="p">[</span><span class="n">index_expanded_F_reordered</span><span class="p">]</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_F_subsample</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">data_F_reordered_subsample</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># iii) Index expansion can also be performed by the indexer of a tensor;</span>
<span class="c1"># this is usually more convenient</span>
<span class="n">index_expanded_F_alt</span> <span class="o">=</span> <span class="n">data_F</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">expand_index</span><span class="p">(</span><span class="n">index_reduced</span><span class="p">)</span>
<span class="n">index_expanded_G_alt</span> <span class="o">=</span> <span class="n">data_G</span><span class="o">.</span><span class="n">indexer</span><span class="o">.</span><span class="n">expand_index</span><span class="p">(</span><span class="n">index_reduced</span><span class="p">)</span>
<span class="n">data_F_subsample_alt</span> <span class="o">=</span> <span class="n">data_F</span><span class="p">[</span><span class="n">index_expanded_F_alt</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span>
<span class="n">data_G_subsample_alt</span> <span class="o">=</span> <span class="n">data_G</span><span class="p">[</span><span class="n">index_expanded_G_alt</span><span class="o">.</span><span class="n">tuple</span><span class="p">]</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">data_F_subsample</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">data_F_subsample_alt</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">data_F_subsample</span> <span class="o">-</span> <span class="n">data_F_subsample_alt</span><span class="p">)</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># Inverse operation is index_reduction (only possible when index is cartesian product)</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">index_expanded_F</span><span class="o">.</span><span class="n">is_reducible</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">))</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">index_expanded_F</span><span class="o">.</span><span class="n">reduce_to_dims</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">index_reduced</span><span class="o">.</span><span class="n">tensor</span> <span class="o">==</span> <span class="n">index_expanded_G</span><span class="o">.</span><span class="n">reduce_to_dims</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="c1"># Illustrate nonseparable case</span>
<span class="n">inseparable_index</span> <span class="o">=</span> <span class="n">CalipyIndex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">]),</span> <span class="n">data_dims_F</span><span class="p">)</span>
<span class="n">inseparable_index</span><span class="o">.</span><span class="n">is_reducible</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span>
<span class="n">inseparable_index</span><span class="o">.</span><span class="n">reduce_to_dims</span><span class="p">(</span><span class="n">batch_dims_FG</span><span class="p">)</span> <span class="c1"># Produces a warning as it should</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.block_subsample">
<span class="sig-name descname"><span class="pre">block_subsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample_sizes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.block_subsample" title="Permalink to this definition"></a></dt>
<dd><p>Generate indices for block subbatching across multiple batch dimensions
and extract the subbatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_dims</strong> – DimTuple with dims along which subbatching happens</p></li>
<li><p><strong>subsample_sizes</strong> – Tuple with sizes of the blocks to create.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of tensors and CalipyIndex representing the block subatches.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.create_block_subsample_indices">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_block_subsample_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample_sizes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.create_block_subsample_indices" title="Permalink to this definition"></a></dt>
<dd><p>Create a CalipyIndex that indexes only the specified batch_dims.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_dims</strong> – DimTuple of batch dimensions to index.</p></li>
<li><p><strong>tensor_shape</strong> – List containing the sizes of the unsubsampled tensor</p></li>
<li><p><strong>subsample_sizes</strong> – Sizes for subsampling along each batch dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of CalipyIndex instances indexing the batch_dims.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.create_global_index">
<span class="sig-name descname"><span class="pre">create_global_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subsample_indextensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_source_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.create_global_index" title="Permalink to this definition"></a></dt>
<dd><p>Create a global CalipyIndex object enumerating all possible indices for all the dims. The
indices global_index_tensor are chosen such that they can be used to access the data
in data_source with name data_source_name via self.tensor  = data_source[global_index_tensor_tuple]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subsample_indextensor</strong> – An index tensor that enumerates for all the entries of
self.tensor which index needs to be used to access it in some global dataset.</p></li>
<li><p><strong>data_source_name</strong> – A string serving as info to record which object the global indices are indexing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A CalipyIndex object global index containing indexing data that
describes how the tensor is related to the superpopulation it has been
sampled from.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.create_local_index">
<span class="sig-name descname"><span class="pre">create_local_index</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.create_local_index" title="Permalink to this definition"></a></dt>
<dd><p>Create a local index tensor enumerating all possible indices for all the dims.
The indices local_index_tensor are chosen such that they can be used for 
indexing the tensor via value = tensor[i,j,k] = tensor[local_index_tensor[i,j,k,:]],
i.e. the index at [i,j,k] is [i,j,k]. A more compact form of indexing
is given by directly accessing the index tuples via tensor = tensor[local_index_tensor_tuple]</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Writes torch tensors with indices representing all possible positions into the index
local_index.tensor: index_tensor containing an index at each location of value in tensor
local_index.tuple: index_tensor split into tuple for straightforward indexing</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.create_simple_subsample_indices">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_simple_subsample_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_dim_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.create_simple_subsample_indices" title="Permalink to this definition"></a></dt>
<dd><p>Create a CalipyIndex that indexes only the specified singular batch_dim.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_dim</strong> – Element of DimTuple (typically CalipyDim) along which
subbatching happens.</p></li>
<li><p><strong>batch_dim_size</strong> – The integer size of the unsubsampled tensor</p></li>
<li><p><strong>subsample_size</strong> – Single integer size determining length of batches to create.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of CalipyIndex instances indexing the batch_dim.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.expand_index">
<span class="sig-name descname"><span class="pre">expand_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index_reduced</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.expand_index" title="Permalink to this definition"></a></dt>
<dd><p>Expand the CalipyIndex index_reduced to align with the dimensions self.dims
of the current tensor self.tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>index_reduced</strong> – A CalipyIndex instance whosed dims are a subset of the
dims of the current tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new CalipyIndex instance with the expanded index tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.reorder">
<span class="sig-name descname"><span class="pre">reorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">order_dimtuple</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.reorder" title="Permalink to this definition"></a></dt>
<dd><p>Generate out of self.tensor a new tensor that is reordered to align with
the order given in the order_dimtuple DimTuple object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>order_dimtuple</strong> – DimTuple of CalipyDim objects whose sequence determines
permutation and index binding of the produced tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor with an calipy.indexer where all ordering is aligned to order_dimtuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="calipy.core.tensor.TensorIndexer.simple_subsample">
<span class="sig-name descname"><span class="pre">simple_subsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.TensorIndexer.simple_subsample" title="Permalink to this definition"></a></dt>
<dd><p>Generate indices for subbatching across a single batch dimension and 
extract the subbatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_dim</strong> – Element of DimTuple (typically CalipyDim) along which
subbatching happens.</p></li>
<li><p><strong>subsample_size</strong> – Single size determining length of batches to create.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of tensors and CalipyIndex representing the subbatches.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="calipy.core.tensor.broadcast_dims">
<span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">broadcast_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims_2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.broadcast_dims" title="Permalink to this definition"></a></dt>
<dd><p>Check if DimTuples <code class="docutils literal notranslate"><span class="pre">dims_1</span></code> and <code class="docutils literal notranslate"><span class="pre">dims_2</span></code> can be broadcasted together and,
if so, produces a new DimTuple that employs PyTorch’s broadcasting logic on
extended dims. Unlike a simple right-to-left alignment, this version explicitly
pads DimTuples towards a consistent superDimTuple with dims of size=1 where
dims need to be injected for consistency. Then pytorchs broadcasting functionality
is called on the extended shapes.</p>
<p>This helps avoid the scenario where the last dimension of one tensor is
matched with the first dimension of another just because of naive negative
indexing. We thereby do not fully emulate how PyTorch handles missing dims
but achieve a more dimension aware broadcast.</p>
<dl class="simple">
<dt>Steps:</dt><dd><ol class="arabic simple">
<li><p>Merge dimension name sequences into a minimal supersequence.</p></li>
<li><p>Expand each DimTuple to that full name list, filling size=1
for missing dims.</p></li>
<li><p>Let PyTorch do shape-based broadcasting.</p></li>
<li><p>Build a final DimTuple from the broadcasted shape, reusing
dimension names from the supersequence.</p></li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dims_1</strong> (<em>DimTuple</em><em> or </em><em>None</em>) – The first DimTuple to broadcast, or None/empty to indicate no dims.</p></li>
<li><p><strong>dims_2</strong> (<em>DimTuple</em><em> or </em><em>None</em>) – The second DimTuple to broadcast, or None/empty to indicate no dims.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A DimTuple reflecting the broadcasted shape if compatible, otherwise None.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DimTuple or None</p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">calipy.core.tensor</span> <span class="kn">import</span> <span class="n">CalipyTensor</span><span class="p">,</span> <span class="n">broadcast_dims</span>
<span class="kn">from</span> <span class="nn">calipy.core.utils</span> <span class="kn">import</span> <span class="n">Dim</span><span class="p">,</span> <span class="n">DimTuple</span><span class="p">,</span> <span class="n">dim_assignment</span>

<span class="c1"># Suppose we have:</span>
<span class="c1">#   c_cp of shape [2, 1], dims=(&#39;dim1&#39;,&#39;dim2&#39;)</span>
<span class="c1">#   b_cp of shape [2],    dims=(&#39;dim1&#39;,)</span>
<span class="c1"># This function ensures the second tensor is padded to [1,2],</span>
<span class="c1"># then does standard broadcasting, leading to final shape [2,2].</span>
<span class="c1"># We unify dimension names accordingly.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="calipy.core.tensor.build_dim_supersequence">
<span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">build_dim_supersequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.build_dim_supersequence" title="Permalink to this definition"></a></dt>
<dd><p>Builds a minimal supersequence of dimension names that contains seq1 and seq2
as subsequences in the same relative order. Names that appear in both sequences
are placed (and unified) only once, if they appear in a non-contradictory order.</p>
<p>If no valid ordering is possible (e.g., seq1 = [dim1, dim2] and seq2 = [dim2, dim1]),
this raises a ValueError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seq1</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – The first dimension name sequence (list of strings).</p></li>
<li><p><strong>seq2</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – The second dimension name sequence (list of strings).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A minimal supersequence (list of strings) that includes seq1 and seq2
in order, unifying repeated names.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[str]</p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Good case:</span>
<span class="n">seq1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim1&#39;</span><span class="p">,</span><span class="s1">&#39;dim2&#39;</span><span class="p">]</span>
<span class="n">seq2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim2&#39;</span><span class="p">,</span><span class="s1">&#39;dim3&#39;</span><span class="p">]</span>
<span class="n">supersequence</span> <span class="o">=</span> <span class="n">build_dim_supersequence</span><span class="p">(</span><span class="n">seq1</span><span class="p">,</span> <span class="n">seq2</span><span class="p">)</span>
<span class="c1"># =&gt; supersequence = [&#39;dim1&#39;,&#39;dim2&#39;,&#39;dim3&#39;,&#39;dim4&#39;]</span>

<span class="c1"># More complicated case</span>
<span class="n">seq1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim1&#39;</span><span class="p">,</span> <span class="s1">&#39;dim2&#39;</span><span class="p">,</span> <span class="s1">&#39;dim4&#39;</span><span class="p">]</span>
<span class="n">seq2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim2&#39;</span><span class="p">,</span>  <span class="s1">&#39;dim3&#39;</span><span class="p">,</span> <span class="s1">&#39;dim4&#39;</span><span class="p">]</span>
<span class="n">supersequence</span> <span class="o">=</span> <span class="n">build_dim_supersequence</span><span class="p">(</span><span class="n">seq1</span><span class="p">,</span> <span class="n">seq2</span><span class="p">)</span>
<span class="c1"># =&gt; supersequence  = [&#39;dim1&#39;, &#39;dim2&#39;, &#39;dim3&#39;, &#39;dim4&#39;]</span>

<span class="c1"># Even more complicated case:</span>
<span class="n">seq1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim1&#39;</span><span class="p">,</span> <span class="s1">&#39;dim2&#39;</span><span class="p">,</span> <span class="s1">&#39;dim4&#39;</span><span class="p">,</span> <span class="s1">&#39;dim5&#39;</span><span class="p">]</span>
<span class="n">seq2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim2&#39;</span><span class="p">,</span>  <span class="s1">&#39;dim3&#39;</span><span class="p">,</span> <span class="s1">&#39;dim4&#39;</span><span class="p">,</span> <span class="s1">&#39;dim6&#39;</span><span class="p">]</span>
<span class="n">supersequence</span> <span class="o">=</span> <span class="n">build_dim_supersequence</span><span class="p">(</span><span class="n">seq1</span><span class="p">,</span> <span class="n">seq2</span><span class="p">)</span>
<span class="c1"># =&gt; supersequence  = [&#39;dim1&#39;, &#39;dim2&#39;, &#39;dim3&#39;, &#39;dim4&#39;, &#39;dim5&#39;, &#39;dim6&#39;]  </span>

<span class="c1"># Contradiction:</span>
<span class="n">seq1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim1&#39;</span><span class="p">,</span><span class="s1">&#39;dim2&#39;</span><span class="p">]</span>
<span class="n">seq2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dim2&#39;</span><span class="p">,</span><span class="s1">&#39;dim1&#39;</span><span class="p">]</span>
<span class="n">supersequence</span> <span class="o">=</span> <span class="n">build_dim_supersequence</span><span class="p">(</span><span class="n">seq1</span><span class="p">,</span> <span class="n">seq2</span><span class="p">)</span>
<span class="c1"># =&gt; raises ValueError</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="calipy.core.tensor.preprocess_args">
<span class="sig-prename descclassname"><span class="pre">calipy.core.tensor.</span></span><span class="sig-name descname"><span class="pre">preprocess_args</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#calipy.core.tensor.preprocess_args" title="Permalink to this definition"></a></dt>
<dd><p>Recursively preprocesses and unwraps input arguments and keyword arguments
by replacing any nested CalipyTensor objects with their underlying torch.Tensor 
instances. Supports arbitrary nesting including dictionaries, lists, tuples, and sets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>tuple</em>) – Positional arguments potentially containing nested CalipyTensor
instances.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – Keyword arguments potentially containing nested CalipyTensor
instances.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple consisting of unwrapped positional arguments and keyword arguments
with all CalipyTensor instances replaced by torch.Tensor objects.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple, dict)</p>
</dd>
</dl>
<p>Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and definitions</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">calipy.core.tensor</span> <span class="kn">import</span> <span class="n">CalipyTensor</span><span class="p">,</span> <span class="n">preprocess_args</span>

<span class="c1"># Create sample CalipyTensors</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bd_1&#39;</span><span class="p">])</span>
<span class="n">event_dims</span> <span class="o">=</span> <span class="n">dim_assignment</span><span class="p">(</span><span class="n">dim_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ed_1&#39;</span><span class="p">])</span>
<span class="n">data_dims</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="n">event_dims</span>
<span class="n">tensor_a</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dims</span> <span class="o">=</span> <span class="n">data_dims</span><span class="p">)</span>
<span class="n">tensor_b</span> <span class="o">=</span> <span class="n">CalipyTensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">dims</span> <span class="o">=</span> <span class="n">data_dims</span><span class="p">)</span>

<span class="c1"># Nested structure containing CalipyTensors</span>
<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">tensor_a</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;key1&#39;</span><span class="p">:</span> <span class="n">tensor_b</span><span class="p">,</span> <span class="s1">&#39;key2&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">tensor_a</span><span class="p">,</span> <span class="mi">10</span><span class="p">]})</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;param&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;nested&#39;</span><span class="p">:</span> <span class="n">tensor_b</span><span class="p">}}</span>

<span class="n">unwrapped_args</span><span class="p">,</span> <span class="n">unwrapped_kwargs</span> <span class="o">=</span> <span class="n">preprocess_args</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unwrapped_args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unwrapped_args</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;key1&#39;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unwrapped_kwargs</span><span class="p">[</span><span class="s1">&#39;param&#39;</span><span class="p">][</span><span class="s1">&#39;nested&#39;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<table class="autosummary longtable docutils align-default">
<tbody>
</tbody>
</table>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="generated/calipy.core.utils.html" class="btn btn-neutral float-left" title="calipy.core.utils" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="data.html" class="btn btn-neutral float-right" title="calipy.core.data (API)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024 - 20255, Dr. Jemil Avers Butt.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>